# Geoextract NL

Off late we have observed that Google Geocoder API is not very good at handling addresses for Netherlands. In order to address this issue the business decided to use the Dutch government data provided in public domain to be put to use as a supportive feature to Google Geocoder and help cleanse the inventory data as a one time task.

This repository will help you guide through the entire process of building this dataset as none of the websites document this properly or have outdated systems or the resources are paid.

### Prerequisites

---

-   Windows machine with atleast 8GB RAM and 6 core CPU, more the better.
-   HDD/SDD having atleast 80GB free space after installing below software
-   Locally installed [MongoDB](https://www.mongodb.com/try/download/community 'MongoDB Community edition download link') or access to some server where you can dump the final dataset.
-   Latest stable version of [QGIS](https://qgis.org/en/site/forusers/download.html 'QGIS download link') installed
-   Latest LTS of [NodeJS](https://nodejs.org/en/download/ 'NodeJS download link') installed
-   Latest version of [Geon BAG Extractor](https://geon.nl/downloads/GeonBAGExtractConversie.php 'Geon BAG Extractor download link'). (You may have to find it in Geon.nl website if this link stops working)

The raw data is available at Dutch [National Geo Register](http://geodata.nationaalgeoregister.nl/inspireadressen/extract/inspireadressen.zip 'Geon BAG Extractor download link') website where the it gets updated every first half of the month. It is generally around 1.8GB of compressed XML files which when unpacked takes around 12GB of disk space.

If you have everything handy then let's kick off `EXTRACTION`. :metal:

## Extraction Stage

---

Bulk of the task will be performed by the BAG extractor tool which is released as a freeware (Thanks to Geon else it would be a nightmare to look through all the XML files in Dutch). Geon offers various other tools for land mapping and tend to keep it updated whenever Geo Register changes their format. Let us look at how to use it now.

English version of this tool is not available, hence the screeshots below should help you operate it.

![Main Screen](/screenshots/Image_1.jpg 'Main Screen of BAG Extractor')

The **(1) Download** button should help you get the RAW file in case you missed it previously. While things are getting ready lets decide on what kind of data we would like to extract by changing some **(5) Settings**.

If you already have the _inspireadressen.zip_ handy then click on **(2) Open** and select the file from your saved location to read basic information. You will be able to see the list of municipalities and the zip file location in **(6) Scope selector** area. This area helps you extract all or subset of data that you need to use. Since we need for entire country we can click the checkbox to select all municipalities. Before proceeding further finalise your scope of extraction by changing the **(5) Settings**.

![Settings](/screenshots/Image_2.jpg 'Settings panel of BAG Extractor')

While the settings shown above should work for any system configuration, but you are free to change it as per your need. The **(A) Log level** will show you the messages generated by the tool, _Info_ should be just fine. Set the number for files for **(D) Parallel indexing** and maximum amount of geometrical points per file to be generated using **(C) ShapeMaximum** attribute.

Offical Geo Register uses _EPSG:28992_ projection (commonly referred as [Amersfoort / RD Projection](https://nl.wikipedia.org/wiki/Rijksdriehoeksco%C3%B6rdinaten 'RD Wiki link')) which gives the geographical coordinates in Easting/Northing (X,Y) pair. All our web mapping features use _EPSG:4326_ ( or [WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System 'WGS84 GIS Wiki link')) projection, hence needs a bit of conversion. Though the tool supports it natively by using **(B) Projection** settings, we have observed some deviations due to older DLL files used by it. Our Tranformation code will take care of it later so just set value as _RD_ for now.

The status filters in the settings panel help you reduce the data set. By default all options are enabled and you need to keep only the relevant ones. Let us look into each of the settings marked from **(E) - (K)**. Each attribute dialog has been translated below and we are using the ones in bold.

![Status Filters 1](/screenshots/Image_3.jpg 'Status filters set 1 of BAG Extractor')
![Status Filters 2](/screenshots/Image_4.jpg 'Status filters set 2 of BAG Extractor')

Once you are satisfied with all the settings save it by clicking on **(L) Confirm**.

Click **(3) Unpack** to start the indexing process which will extract all the zip files, will take around 10 - 15 mins. You can choose to save the extracted files in a different location. After completion click on **(4) Convert** button to see the following dialog.

![Converter Settings](/screenshots/Image_5.jpg 'Converter settings of BAG Extractor')

You will find several options for loading the extracted data to RDBMS or Excel but _they never work_ due to several technical issues with its drivers. Therefore choosing the _ShapeFiles_ option is our best bet. Select a custom folder where you would like to store these GIS Shape files and click on **Converteer**.

From this point on your machine might be on :fire: and take upto 1 - 5 hours depending on your gig. While this happens you may :stew:/:beers:/:sleeping:. Ensure your :computer: is :electric_plug: in with enough :battery: backup and it doesnt sleep or shut down until the process ends. You may be tempted to close the program if it doesnt respond but believe me it doesnt help at all. Let it run... :laughing:

## Transformation and Loading Stage

---

Once the extraction process ends note the output directory of Shape file and now it is time to transform our data and load it to Mongo. Clone this repository or donwload the zip from Github

    git clone https://github.com/sandeepk01/geoextract-nl.git

If you havent used yarn before run following commands to set all up.

    npm install -g yarn
    cd geoextract_nl
    yarn install

Now change the parameters in **extractor.js** file for below lines pointing to respective locations as per your settings

![Project Settings](/screenshots/Image_6.jpg 'Project settings')

-   _numDataPath_ : Location where ShapeFiles are stored. Note the path escaping in the string.
-   _ogrPath_ : Location where **ogr2ogr.exe** is present when QGIS got installed.
-   _pool_ : Adjust the **maxWorkers** attribute based on your CPU cores. (Optional)
-   _doProjection_ : Toggle to either choose GDAL OGR executable to transform the geo data or use the settings mentioned in the project (Proj4).

Additionally if you want to push to a different MongoDB instance (remote) then you can change the connection settings mentioned in **helpers/mongoUtils.js** file.

Once you are satisfied with these settings run below command to start the process.

    yarn etl

This takes around 30-40 mins and is done in 3 stages. It may take more based on available resources and network while connecting to remote DB.

-   **Stage 1**: Shapefiles (.shp) are passed through GDAL OGR driver to get a GeoJSON. This will output many duplicates and nullish values.
-   **Stage 2**: Every GeoJSON is taken through the data transformer which carefully looks into every data and creates a list of values that are fit to load onto database. This is a CPU intensive process hence runs in parallel threads, creating staging JSON files.
-   **Stage 3**: All the staging JSON files are not now loaded onto database one by one.

If any of the step fails, the subsequent ones wont run until the errors are fixed. Finally you will get more than **_9 million unique addresses (around 1.2GB)_** of data loaded onto MongoDB for direct use.

![Sample Data](/screenshots/Image_7.jpg 'Sample address')

Attributes until municipality has been transformed as per our operational needs while other attributes below it are original for reference purposes.

Any suggestions/PR welcome.

Cheers! :+1: :tada:

---

**DISCLAIMER: Kindly use the data extracted as per GDPR guidelines.**
